{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bog-9ygSgek6"
      },
      "source": [
        "# Optimizing the model with series of experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_9wLOENogek9"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEeiI5Ekgek-"
      },
      "source": [
        "### LetÂ´s first reload the data from the previous notebook. Then, perform train_test_split once again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "YHwaGfg_gek_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/arthur/Documentos/Insper/6_semestre/projetos_ml/AmesHousingDataset/data\n"
          ]
        }
      ],
      "source": [
        "DATA_DIR = pathlib.Path.cwd().parent / 'data'\n",
        "print(DATA_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "AGH-oL7rgek_"
      },
      "outputs": [],
      "source": [
        "model_data_scaled_path = DATA_DIR / 'processed' / 'ames_model_data_scaled.pkl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Z7Y5Iacjgek_"
      },
      "outputs": [],
      "source": [
        "data = pd.read_pickle(model_data_scaled_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "jj5g9uDugek_"
      },
      "outputs": [],
      "source": [
        "X = data.drop(columns=['SalePrice']).copy().values\n",
        "y = data['SalePrice'].copy().values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "siGQ3G7ggelA"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((2877, 164), (2877,))"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "3nm7_WOdgelA"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 42  # Any number here, really.\n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.25,\n",
        "    random_state=RANDOM_SEED,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9fYbEhHgelA"
      },
      "source": [
        "### Experiment 1: LinearRegression with transformed values\n",
        "\n",
        "Our first experiment is to rerun the linear regression model with the same features as before, but this time on the new data with the transformations applied on the previous notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5msGTsiwgelB"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wesTDvkUgelB"
      },
      "outputs": [],
      "source": [
        "linear_scaled_model = LinearRegression()\n",
        "\n",
        "linear_scaled_model.fit(Xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this and the following experiments, we will also use cross_val_score instead of simply predicting on the test set. This will give us a better idea of how the model will perform on unseen data, given that we are making more realistic performance estimates, and the variance of the model evaluation will be lower."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAh5ZQ6CgelB"
      },
      "outputs": [],
      "source": [
        "scores_linear_scaled = cross_val_score(linear_scaled_model,\n",
        "                                       Xtrain,\n",
        "                                       ytrain,\n",
        "                                       cv=10,\n",
        "                                       scoring='neg_mean_squared_error',\n",
        "                                       n_jobs=-1)\n",
        "\n",
        "scores_linear_scaled = np.sqrt(-scores_linear_scaled)\n",
        "error_percent_linear = 100 * (10**scores_linear_scaled.mean() - 1)\n",
        "std_percent_linear = 100 * (10**scores_linear_scaled.std() - 1)\n",
        "print(f'Average error is {error_percent_linear:.2f}%')\n",
        "print(f'Standard deviation of error is {std_percent_linear:.2f}%')\n",
        "\n",
        "path = DATA_DIR / 'processed' / 'linear_scaled_model.csv'\n",
        "\n",
        "# write the array scores_linear_scaled to a csv file\n",
        "\n",
        "np.savetxt(path, scores_linear_scaled, delimiter=',')\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWJxJtLFgelB"
      },
      "source": [
        "The experiment showed no large difference in the model performance, considering the standard deviation. This means that the LinearRegression model is not sensitive to the new transformations we made on the data. We will, however, still keep the new data for the next experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO88AXX_gelB"
      },
      "source": [
        "### Experiment 2: Lasso Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Lasso Regression is similar to the Linear Regression, but it adds a regularization term to the cost function, which penalizes the model for having too many features (in this case, the L1 norm of the weights). This is useful to avoid overfitting, and also to perform feature selection, since the regularization term will make the weights of the less important features go to zero.\n",
        "\n",
        "We can define this regularization term as:\n",
        "\n",
        "$$\n",
        "\\lambda \\sum_{i=1}^{n} |w_i|\n",
        "$$\n",
        "\n",
        "Where $\\lambda$ is the regularization parameter, and $w_i$ is the weight of the $i$-th feature.\n",
        "\n",
        "As $w_i$ gets closer to zero, the regularization term will also get closer to zero, and the model will be penalized less. This means that the model will try to minimize the cost function by making the weights of the less important features go to zero, and the weights of the most important features will be kept as they are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxfujoYXgelC"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Lasso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this and the following experiments, we will use GridSearchCV to find better values for model hyperparameters. This will allow us to perform a more thorough search in the hyperparameter space, and find the best model for our data without having to manually test different values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-FnepU-gelC"
      },
      "outputs": [],
      "source": [
        "lasso = Lasso()\n",
        "\n",
        "params = {\n",
        "    'alpha': np.logspace(-4, 0, 100),\n",
        "    'max_iter': [15000, 20000, 30000],\n",
        "    'tol': [0.0001, 0.001],\n",
        "    'selection': ['cyclic', 'random'],\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(lasso, params, cv=5, verbose=1, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5OrzY5PgelC"
      },
      "outputs": [],
      "source": [
        "grid.fit(Xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get the best parameters for Lasso Regression, from the grid search, and use them to train a new model. Then, evaluate the model using cross_val_score:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJIt31ZrgelC"
      },
      "outputs": [],
      "source": [
        "best_params = grid.best_params_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYjhHl-GgelC"
      },
      "outputs": [],
      "source": [
        "lasso_best = Lasso(**best_params)\n",
        "lasso_best.fit(Xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8wba6J7gelC"
      },
      "outputs": [],
      "source": [
        "scores_lasso = cross_val_score(lasso_best, Xtrain, ytrain, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "scores_lasso = np.sqrt(-scores_lasso)\n",
        "error_percent_lasso = 100 * (10**scores_lasso.mean() - 1)\n",
        "std_percent_lasso = 100 * (10**scores_lasso.std() - 1)\n",
        "print(f'Average error is {error_percent_lasso:.2f}%')\n",
        "print(f'Standard deviation of error is {std_percent_lasso:.2f}%')\n",
        "\n",
        "path = DATA_DIR / 'processed' / 'lasso_score.csv'\n",
        "\n",
        "np.savetxt(path, scores_lasso, delimiter=',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experiment 3: Ridge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Ridge Regression is similar to the Linear Regression, but it adds a regularization term to the cost function, which penalizes the model for having too many features (in this case, the L2 norm of the weights). This is useful to avoid overfitting, and also to perform feature selection, since the regularization term will make the weights of the less important features go to zero.\n",
        "\n",
        "We can define this regularization term as:\n",
        "\n",
        "$$\n",
        "\\lambda \\sum_{i=1}^{n} w_i^2\n",
        "$$\n",
        "\n",
        "Where $\\lambda$ is the regularization parameter, and $w_i$ is the weight of the $i$-th feature.\n",
        "\n",
        "Differently from the Lasso Regression, the Ridge Regression will not make the weights of the less important features go to zero, but it will make them very small (since $w_i$ is squared, it will be even smaller than in the Lasso Regression)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Ridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ridge = Ridge()\n",
        "\n",
        "params = {\n",
        "    'alpha': np.logspace(-4, 0, 100),\n",
        "    'fit_intercept': [True, False],\n",
        "    'copy_X': [True, False],\n",
        "    'max_iter': [15000, 20000, 30000],\n",
        "    'tol': [0.0001, 0.001],\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(ridge, params, cv=5, verbose=1, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid.fit(Xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_params = grid.best_params_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ridge_best = Ridge(**best_params)\n",
        "ridge_best.fit(Xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores_ridge = cross_val_score(ridge_best, Xtrain, ytrain, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "scores_ridge = np.sqrt(-scores_ridge)\n",
        "error_percent_ridge = 100 * (10**scores_ridge.mean() - 1)\n",
        "std_percent_ridge = 100 * (10**scores_ridge.std() - 1)\n",
        "print(f'Average error is {error_percent_ridge:.2f}%')\n",
        "print(f'Standard deviation of error is {std_percent_ridge:.2f}%')\n",
        "\n",
        "path = DATA_DIR / 'processed' / 'ridge.csv'\n",
        "\n",
        "np.savetxt(path, scores_ridge, delimiter=',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experiment 4:  Decision Tree Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Decision trees are a type of algorithm used mostly for classification, since they are easy to interpret and visualize. However, they can also be used for regression. \n",
        "\n",
        "From our exploratory analysis, we know that most variables form a linear relationship, however it is still a good itea to test this model because it is a non-parametric model, which means that it does not make any assumptions about the data distribution. This means that it can capture relationships that linear models cannot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A decision tree is a tree where each node represents a feature (or a group of features), each link represents a decision (resulting from a feature split), and each leaf represents an output (a prediction). The tree is built by splitting the data into subsets, and then splitting it again on each of the subsets, and so on, until the subsets are small enough to be represented by a leaf.\n",
        "\n",
        "As for hyperparameters, we can specify:\n",
        "- min_samples_split: the minimum number of samples required to split an internal node\n",
        "- min_samples_leaf: the minimum number of samples required to be at a leaf node\n",
        "- min_weight_fraction_leaf: the minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node\n",
        "- max_features: the number of features to consider when looking for the best split\n",
        "- min_impurity_decrease: a node will be split if this split induces a decrease of the impurity greater than or equal to this value\n",
        "- ccp_alpha: complexity parameter used for Minimal Cost-Complexity Pruning\n",
        "\n",
        "We will leave max_depth as None, so the nodes will be expanded until all leaves are pure or until all leaves contain less than min_samples_split samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tree = DecisionTreeRegressor()\n",
        "\n",
        "params = {\n",
        "    'min_samples_split': [2, 3, 4],\n",
        "    'min_samples_leaf': [1, 2, 3],\n",
        "    'min_weight_fraction_leaf': [0, 0.01, 0.1],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'min_impurity_decrease': [0, 0.01, 0.1],\n",
        "    'ccp_alpha': [0, 0.01, 0.1]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(tree, params, cv=5, verbose=1, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid.fit(Xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_params = grid.best_params_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tree_best = DecisionTreeRegressor(**best_params)\n",
        "tree_best.fit(Xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores_tree = cross_val_score(tree_best, Xtrain, ytrain, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "scores_tree = np.sqrt(-scores_tree)\n",
        "error_percent_tree = 100 * (10**scores_tree.mean() - 1)\n",
        "std_percent_tree = 100 * (10**scores_tree.std() - 1)\n",
        "print(f'Average error is {error_percent_tree:.2f}%')\n",
        "print(f'Standard deviation of error is {std_percent_tree:.2f}%')\n",
        "\n",
        "path = 'tree_scores.csv'\n",
        "\n",
        "np.savetxt(path, scores_tree, delimiter=',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLGdIqIEgelD"
      },
      "source": [
        "### Experiment 5:  Random Forest Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The random forest is very similar to the decision tree, but it uses a technique called bagging to reduce the variance of the model, by training many decision trees on different subsets of the data, and then averaging the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqhuSZ7JgelD"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBn1PDHPgelD"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestRegressor()\n",
        "\n",
        "params = {\n",
        "    'n_estimators': [100, 600, 1200, 1800],\n",
        "    'min_samples_split': [3],\n",
        "    'max_features': ['auto', 'sqrt'],\n",
        "    'verbose': [0, 1, 2, 3],\n",
        "    'max_depth': [None],\n",
        "    'bootstrap': [False],\n",
        "    'min_weight_fraction_leaf': [0.0],\n",
        "    'min_samples_leaf': [1],\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(rf, params, cv=5, verbose=1, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncBy3F-igelD"
      },
      "outputs": [],
      "source": [
        "grid.fit(Xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqEhl9WZgelD",
        "outputId": "625ba6f2-518f-4c9c-e6c1-45e8f75a6d78"
      },
      "outputs": [],
      "source": [
        "best_params = grid.best_params_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s88tM9SRgelD"
      },
      "outputs": [],
      "source": [
        "rf_best = RandomForestRegressor(**best_params)\n",
        "rf_best.fit(Xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwrovDvzgelE"
      },
      "outputs": [],
      "source": [
        "scores_rf = cross_val_score(rf_best, Xtrain, ytrain, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "scores_rf = np.sqrt(-scores_rf)\n",
        "error_percent_rf = 100 * (10**scores_rf.mean() - 1)\n",
        "std_percent_rf = 100 * (10**scores_rf.std() - 1)\n",
        "print(f'Average error is {error_percent_rf:.2f}%')\n",
        "print(f'Standard deviation of error is {std_percent_rf:.2f}%')\n",
        "\n",
        "path = DATA_DIR / 'processed' / 'rf_scores.csv'\n",
        "\n",
        "np.savetxt(path, scores_rf, delimiter=',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHU1A47NgelE"
      },
      "source": [
        "### Experiment 6:  Gradient Boosting Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gradient boosting is a technique that combines weak learners (in this case, decision trees) to create a strong learner. It is similar to the random forest, but instead of training each tree independently, it trains each tree on the residual of the previous tree.\n",
        "\n",
        "We can define the gradient boosting algorithm as:\n",
        "\n",
        "$$\n",
        "F_0(x) = \\underset{\\gamma}{\\arg\\min} \\sum_{i=1}^{n} L(y_i, \\gamma)\n",
        "$$\n",
        "\n",
        "$$\n",
        "F_m(x) = F_{m-1}(x) + \\underset{\\gamma}{\\arg\\min} \\sum_{i=1}^{n} L(y_i, F_{m-1}(x_i) + \\gamma h_m(x_i))\n",
        "$$\n",
        "\n",
        "Where $F_0(x)$ is the first tree (obtained by minimizing $L(y_i, \\gamma)$ over the training data), $F_m(x)$ is the $m$-th tree, $L$ is the loss function, $y_i$ is the target value, $x_i$ is the $i$-th feature vector, and $h_m(x_i)$ is the prediction of the $m$-th tree.\n",
        "\n",
        "The technique uses the gradient descent algorithm to minimize the loss function, and the trees are added sequentially, so the model is built in a stage-wise fashion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGfMjeHbgelE"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7T6lq5tBgelE"
      },
      "outputs": [],
      "source": [
        "gbr = GradientBoostingRegressor()\n",
        "\n",
        "params = {\n",
        " 'alpha': [0.9], \n",
        " 'criterion': ['friedman_mse'],\n",
        " 'learning_rate': [0.1, 0.5, 0.01], \n",
        " 'max_depth': [3, 4, 5], \n",
        " 'max_features': ['sqrt'], \n",
        " 'min_samples_leaf': [2,3], \n",
        " 'n_estimators': [1600,200], \n",
        " 'subsample': [0.9, 0.8, 0.7, 0.6], \n",
        " 'verbose': [0,1,2], \n",
        " 'warm_start': [True, False]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(gbr, params, cv=5, verbose=1, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQI9A7WXgelE",
        "outputId": "20c2ffb3-69d7-44a2-8145-5c0ca0415bed"
      },
      "outputs": [],
      "source": [
        "grid.fit(Xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTXDdTvPgelE",
        "outputId": "a1d2b7ba-e649-4f85-ac58-96fda1456de5"
      },
      "outputs": [],
      "source": [
        "best_params = grid.best_params_\n",
        "with open('best_params_gradient.txt', 'w') as f:\n",
        "    f.write(str(best_params))\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMFs95wQgelE",
        "outputId": "5bf2a913-83c3-4c18-f6f6-c5280c713979"
      },
      "outputs": [],
      "source": [
        "gbr_best = GradientBoostingRegressor(**best_params)\n",
        "gbr_best.fit(Xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JH_u90FUgelE",
        "outputId": "f50ed70e-93f3-450e-c221-b848fbaf92a9"
      },
      "outputs": [],
      "source": [
        "scores_gbr = cross_val_score(gbr_best, Xtrain, ytrain, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "scores_gbr = np.sqrt(-scores_gbr)\n",
        "error_percent_gbr = 100 * (10**scores_gbr.mean() - 1)\n",
        "std_percent_gbr = 100 * (10**scores_gbr.std() - 1)\n",
        "print(f'Average error is {error_percent_gbr:.2f}%')\n",
        "print(f'Standard deviation of error is {std_percent_gbr:.2f}%')\n",
        "\n",
        "path = DATA_DIR / 'processed' / 'gradient_scores.csv'\n",
        "\n",
        "np.savetxt(path, scores_gbr, delimiter=',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_T2JBDzgelF"
      },
      "source": [
        "### Experiment 7:  KNN Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "KNN is a different non-parametric approach to regression. It is a lazy learning algorithm, which means that it does not learn a function from the training data, but instead memorizes the training data (that is, stores everything on memory) and waits until it is given a new data point to make a prediction.\n",
        "\n",
        "During training, the algorithm simply stores the training data. During testing, the algorithm finds the $k$ nearest neighbors of the new data point, and then averages the target values of the neighbors to make a regression prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "ivWgnFfggelF"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "8wmDaSRYgelF"
      },
      "outputs": [],
      "source": [
        "knn = KNeighborsRegressor()\n",
        "\n",
        "params = {\n",
        "    'n_neighbors': [5, 6, 7, 8],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "    'p': [1, 2, 3],\n",
        "    'leaf_size': [30, 40, 50]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(knn, params, cv=5, verbose=1, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNeighborsRegressor(), n_jobs=-1,\n",
              "             param_grid={&#x27;algorithm&#x27;: [&#x27;auto&#x27;, &#x27;ball_tree&#x27;, &#x27;kd_tree&#x27;, &#x27;brute&#x27;],\n",
              "                         &#x27;leaf_size&#x27;: [30, 40, 50], &#x27;n_neighbors&#x27;: [5, 6, 7, 8],\n",
              "                         &#x27;p&#x27;: [1, 2, 3], &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
              "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNeighborsRegressor(), n_jobs=-1,\n",
              "             param_grid={&#x27;algorithm&#x27;: [&#x27;auto&#x27;, &#x27;ball_tree&#x27;, &#x27;kd_tree&#x27;, &#x27;brute&#x27;],\n",
              "                         &#x27;leaf_size&#x27;: [30, 40, 50], &#x27;n_neighbors&#x27;: [5, 6, 7, 8],\n",
              "                         &#x27;p&#x27;: [1, 2, 3], &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
              "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5, estimator=KNeighborsRegressor(), n_jobs=-1,\n",
              "             param_grid={'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
              "                         'leaf_size': [30, 40, 50], 'n_neighbors': [5, 6, 7, 8],\n",
              "                         'p': [1, 2, 3], 'weights': ['uniform', 'distance']},\n",
              "             verbose=1)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid.fit(Xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "HPB4rVMagelF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'algorithm': 'auto', 'leaf_size': 30, 'n_neighbors': 6, 'p': 1, 'weights': 'distance'}\n"
          ]
        }
      ],
      "source": [
        "best_params = grid.best_params_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "nDd4pnOegelJ"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor(n_neighbors=6, p=1, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor(n_neighbors=6, p=1, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsRegressor(n_neighbors=6, p=1, weights='distance')"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "knn_best = KNeighborsRegressor(**best_params)\n",
        "knn_best.fit(Xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average error is 19.22%\n",
            "Standard deviation of error is 1.09%\n"
          ]
        }
      ],
      "source": [
        "scores_knn = cross_val_score(knn_best, Xtrain, ytrain, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "scores_knn = np.sqrt(-scores_knn)\n",
        "error_percent_knn = 100 * (10**scores_knn.mean() - 1)\n",
        "std_percent_knn = 100 * (10**scores_knn.std() - 1)\n",
        "print(f'Average error is {error_percent_knn:.2f}%')\n",
        "print(f'Standard deviation of error is {std_percent_knn:.2f}%')\n",
        "\n",
        "path = DATA_DIR / 'processed' / 'knn_scores.csv'\n",
        "\n",
        "np.savetxt(path, scores_knn, delimiter=',')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Experiment 8: ElasticNetCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ElasticNet is a combination of Lasso and Ridge regressions, which adds both regularization terms (L1 and L2) to the cost function. This allows the model to learn a sparse model where few of the weights are non-zero like Lasso, while still maintaining the regularization properties of Ridge.\n",
        "\n",
        "We can define this new cost function as:\n",
        "\n",
        "$$\n",
        "\n",
        "\\lambda_1 \\sum_{i=1}^{n} |w_i| + \\lambda_2 \\sum_{i=1}^{n} w_i^2\n",
        "\n",
        "$$\n",
        "\n",
        "Where $\\lambda_1$ and $\\lambda_2$ are the regularization parameters.\n",
        "\n",
        "It is important to note that ElasticNetCV is not a model, but a method that can be used to find the best values for the regularization parameters $\\lambda_1$ and $\\lambda_2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import ElasticNetCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "elnet = ElasticNetCV()\n",
        "\n",
        "params = {\n",
        "    'l1_ratio': [0.6, 0.3, 0.2, 0.1],\n",
        "    'eps': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8],\n",
        "    'n_alphas': [100, 150, 200],\n",
        "    'copy_X': [True, False],\n",
        "    'verbose': [0,1,2]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(elnet, params, cv=5, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "grid.fit(Xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_params = grid.best_params_\n",
        "print(best_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "elnet_best = ElasticNetCV(**best_params)\n",
        "elnet_best.fit(Xtrain, ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scores_elnet = cross_val_score(elnet_best, Xtrain, ytrain, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "scores_elnet = np.sqrt(-scores_elnet)\n",
        "error_percent_elnet = 100 * (10**scores_elnet.mean() - 1)\n",
        "std_percent_elnet = 100 * (10**scores_elnet.std() - 1)\n",
        "print(f'Average error is {error_percent_elnet:.2f}%')\n",
        "print(f'Standard deviation of error is {std_percent_elnet:.2f}%')\n",
        "\n",
        "path = DATA_DIR / 'processed' / 'elnet_scores.csv'\n",
        "\n",
        "np.savetxt(path, scores_elnet, delimiter=',')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wwv4f0XOgelK"
      },
      "source": [
        "### Retraining of best model on the whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkNrXjEkgelK"
      },
      "outputs": [],
      "source": [
        "best_model = linear_scaled_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-GozjutgelK"
      },
      "outputs": [],
      "source": [
        "best_model.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chossing the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "def compare_scores(score1, score2):\n",
        "    t_stat, p_value = ttest_ind(score1, score2, equal_var=False)\n",
        "    print(f'T-statistic: {t_stat:.2f}')\n",
        "    print(f'p-value: {p_value:.2f}')\n",
        "    if p_value < 0.5:\n",
        "        print('Model is better than baseline')\n",
        "    else:\n",
        "        print('Results are not significant')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Linear Scaled Model</th>\n",
              "      <th>Lasso</th>\n",
              "      <th>Ridge</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Random Forest</th>\n",
              "      <th>Gradient Boosting</th>\n",
              "      <th>KNN</th>\n",
              "      <th>Elastic Net</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.072027</td>\n",
              "      <td>0.074151</td>\n",
              "      <td>0.072099</td>\n",
              "      <td>0.098224</td>\n",
              "      <td>0.052702</td>\n",
              "      <td>0.047553</td>\n",
              "      <td>0.074376</td>\n",
              "      <td>0.073719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.044358</td>\n",
              "      <td>0.043487</td>\n",
              "      <td>0.043913</td>\n",
              "      <td>0.082415</td>\n",
              "      <td>0.048090</td>\n",
              "      <td>0.042026</td>\n",
              "      <td>0.073129</td>\n",
              "      <td>0.043525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.045163</td>\n",
              "      <td>0.043955</td>\n",
              "      <td>0.044698</td>\n",
              "      <td>0.079191</td>\n",
              "      <td>0.045496</td>\n",
              "      <td>0.038408</td>\n",
              "      <td>0.074954</td>\n",
              "      <td>0.043873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.073619</td>\n",
              "      <td>0.072708</td>\n",
              "      <td>0.073152</td>\n",
              "      <td>0.097717</td>\n",
              "      <td>0.069103</td>\n",
              "      <td>0.060742</td>\n",
              "      <td>0.087720</td>\n",
              "      <td>0.072671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.049673</td>\n",
              "      <td>0.046664</td>\n",
              "      <td>0.048198</td>\n",
              "      <td>0.084619</td>\n",
              "      <td>0.054938</td>\n",
              "      <td>0.045238</td>\n",
              "      <td>0.070134</td>\n",
              "      <td>0.046859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.040611</td>\n",
              "      <td>0.040680</td>\n",
              "      <td>0.040540</td>\n",
              "      <td>0.082677</td>\n",
              "      <td>0.052312</td>\n",
              "      <td>0.042497</td>\n",
              "      <td>0.074704</td>\n",
              "      <td>0.040572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.051588</td>\n",
              "      <td>0.050013</td>\n",
              "      <td>0.051174</td>\n",
              "      <td>0.092199</td>\n",
              "      <td>0.053761</td>\n",
              "      <td>0.046714</td>\n",
              "      <td>0.077820</td>\n",
              "      <td>0.050328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.042617</td>\n",
              "      <td>0.041405</td>\n",
              "      <td>0.042040</td>\n",
              "      <td>0.068285</td>\n",
              "      <td>0.048096</td>\n",
              "      <td>0.041540</td>\n",
              "      <td>0.072266</td>\n",
              "      <td>0.041271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.046031</td>\n",
              "      <td>0.046415</td>\n",
              "      <td>0.046035</td>\n",
              "      <td>0.089832</td>\n",
              "      <td>0.057975</td>\n",
              "      <td>0.048345</td>\n",
              "      <td>0.079017</td>\n",
              "      <td>0.046150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.056263</td>\n",
              "      <td>0.056120</td>\n",
              "      <td>0.056085</td>\n",
              "      <td>0.082703</td>\n",
              "      <td>0.059759</td>\n",
              "      <td>0.055170</td>\n",
              "      <td>0.079386</td>\n",
              "      <td>0.056046</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Linear Scaled Model     Lasso     Ridge  Decision Tree  Random Forest  \\\n",
              "0             0.072027  0.074151  0.072099       0.098224       0.052702   \n",
              "1             0.044358  0.043487  0.043913       0.082415       0.048090   \n",
              "2             0.045163  0.043955  0.044698       0.079191       0.045496   \n",
              "3             0.073619  0.072708  0.073152       0.097717       0.069103   \n",
              "4             0.049673  0.046664  0.048198       0.084619       0.054938   \n",
              "5             0.040611  0.040680  0.040540       0.082677       0.052312   \n",
              "6             0.051588  0.050013  0.051174       0.092199       0.053761   \n",
              "7             0.042617  0.041405  0.042040       0.068285       0.048096   \n",
              "8             0.046031  0.046415  0.046035       0.089832       0.057975   \n",
              "9             0.056263  0.056120  0.056085       0.082703       0.059759   \n",
              "\n",
              "   Gradient Boosting       KNN  Elastic Net  \n",
              "0           0.047553  0.074376     0.073719  \n",
              "1           0.042026  0.073129     0.043525  \n",
              "2           0.038408  0.074954     0.043873  \n",
              "3           0.060742  0.087720     0.072671  \n",
              "4           0.045238  0.070134     0.046859  \n",
              "5           0.042497  0.074704     0.040572  \n",
              "6           0.046714  0.077820     0.050328  \n",
              "7           0.041540  0.072266     0.041271  \n",
              "8           0.048345  0.079017     0.046150  \n",
              "9           0.055170  0.079386     0.056046  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# reading the scores from the csv files\n",
        "\n",
        "linear_scaled_model_scores = pd.read_csv(DATA_DIR / 'processed' / 'linear_scaled_model.csv', header=None)\n",
        "lasso_scores = pd.read_csv(DATA_DIR / 'processed' / 'lasso_score.csv', header=None)\n",
        "ridge_scores = pd.read_csv(DATA_DIR / 'processed' / 'ridge.csv', header=None)\n",
        "tree_scores = pd.read_csv('tree_scores.csv', header=None)\n",
        "rf_scores = pd.read_csv(DATA_DIR / 'processed' / 'rf_scores.csv', header=None)\n",
        "gradient_scores = pd.read_csv(DATA_DIR / 'processed' / 'gradient_scores.csv', header=None)\n",
        "knn_scores = pd.read_csv(DATA_DIR / 'processed' / 'knn_scores.csv', header=None)\n",
        "elnet_scores = pd.read_csv(DATA_DIR / 'processed' / 'elnet_scores.csv', header=None)\n",
        "\n",
        "# creating dataframes for the scores\n",
        "\n",
        "scores = pd.DataFrame({'Linear Scaled Model': linear_scaled_model_scores[0],\n",
        "                          'Lasso': lasso_scores[0],\n",
        "                          'Ridge': ridge_scores[0],\n",
        "                          'Decision Tree': tree_scores[0],\n",
        "                          'Random Forest': rf_scores[0],\n",
        "                          'Gradient Boosting': gradient_scores[0],\n",
        "                          'KNN': knn_scores[0],\n",
        "                          'Elastic Net': elnet_scores[0]})\n",
        "\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Linear Scaled Model</th>\n",
              "      <th>Lasso</th>\n",
              "      <th>Ridge</th>\n",
              "      <th>Decision Tree</th>\n",
              "      <th>Random Forest</th>\n",
              "      <th>Gradient Boosting</th>\n",
              "      <th>KNN</th>\n",
              "      <th>Elastic Net</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18.039406</td>\n",
              "      <td>18.618029</td>\n",
              "      <td>18.058873</td>\n",
              "      <td>25.378706</td>\n",
              "      <td>12.902003</td>\n",
              "      <td>11.571373</td>\n",
              "      <td>18.679599</td>\n",
              "      <td>18.500209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10.753618</td>\n",
              "      <td>10.531852</td>\n",
              "      <td>10.640198</td>\n",
              "      <td>20.896940</td>\n",
              "      <td>11.709433</td>\n",
              "      <td>10.160616</td>\n",
              "      <td>18.339419</td>\n",
              "      <td>10.541510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.959094</td>\n",
              "      <td>10.650925</td>\n",
              "      <td>10.840292</td>\n",
              "      <td>20.002608</td>\n",
              "      <td>11.044290</td>\n",
              "      <td>9.246500</td>\n",
              "      <td>18.837718</td>\n",
              "      <td>10.630036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18.472854</td>\n",
              "      <td>18.224603</td>\n",
              "      <td>18.345664</td>\n",
              "      <td>25.232430</td>\n",
              "      <td>17.247412</td>\n",
              "      <td>15.011577</td>\n",
              "      <td>22.382611</td>\n",
              "      <td>18.214573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12.117306</td>\n",
              "      <td>11.343301</td>\n",
              "      <td>11.737201</td>\n",
              "      <td>21.511966</td>\n",
              "      <td>13.484891</td>\n",
              "      <td>10.978329</td>\n",
              "      <td>17.526048</td>\n",
              "      <td>11.393218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>9.802179</td>\n",
              "      <td>9.819600</td>\n",
              "      <td>9.784128</td>\n",
              "      <td>20.969728</td>\n",
              "      <td>12.800810</td>\n",
              "      <td>10.279990</td>\n",
              "      <td>18.769361</td>\n",
              "      <td>9.792456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>12.612925</td>\n",
              "      <td>12.205313</td>\n",
              "      <td>12.505571</td>\n",
              "      <td>23.651432</td>\n",
              "      <td>13.177726</td>\n",
              "      <td>11.356051</td>\n",
              "      <td>19.624456</td>\n",
              "      <td>12.286614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10.310585</td>\n",
              "      <td>10.003241</td>\n",
              "      <td>10.164101</td>\n",
              "      <td>17.026733</td>\n",
              "      <td>11.710944</td>\n",
              "      <td>10.037430</td>\n",
              "      <td>18.104336</td>\n",
              "      <td>9.969084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>11.181042</td>\n",
              "      <td>11.279532</td>\n",
              "      <td>11.182026</td>\n",
              "      <td>22.979297</td>\n",
              "      <td>14.281360</td>\n",
              "      <td>11.775034</td>\n",
              "      <td>19.954564</td>\n",
              "      <td>11.211627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>13.831712</td>\n",
              "      <td>13.794283</td>\n",
              "      <td>13.785058</td>\n",
              "      <td>20.977129</td>\n",
              "      <td>14.751629</td>\n",
              "      <td>13.545585</td>\n",
              "      <td>20.056646</td>\n",
              "      <td>13.774879</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Linear Scaled Model      Lasso      Ridge  Decision Tree  Random Forest  \\\n",
              "0            18.039406  18.618029  18.058873      25.378706      12.902003   \n",
              "1            10.753618  10.531852  10.640198      20.896940      11.709433   \n",
              "2            10.959094  10.650925  10.840292      20.002608      11.044290   \n",
              "3            18.472854  18.224603  18.345664      25.232430      17.247412   \n",
              "4            12.117306  11.343301  11.737201      21.511966      13.484891   \n",
              "5             9.802179   9.819600   9.784128      20.969728      12.800810   \n",
              "6            12.612925  12.205313  12.505571      23.651432      13.177726   \n",
              "7            10.310585  10.003241  10.164101      17.026733      11.710944   \n",
              "8            11.181042  11.279532  11.182026      22.979297      14.281360   \n",
              "9            13.831712  13.794283  13.785058      20.977129      14.751629   \n",
              "\n",
              "   Gradient Boosting        KNN  Elastic Net  \n",
              "0          11.571373  18.679599    18.500209  \n",
              "1          10.160616  18.339419    10.541510  \n",
              "2           9.246500  18.837718    10.630036  \n",
              "3          15.011577  22.382611    18.214573  \n",
              "4          10.978329  17.526048    11.393218  \n",
              "5          10.279990  18.769361     9.792456  \n",
              "6          11.356051  19.624456    12.286614  \n",
              "7          10.037430  18.104336     9.969084  \n",
              "8          11.775034  19.954564    11.211627  \n",
              "9          13.545585  20.056646    13.774879  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores_adjusted = scores.copy()\n",
        "\n",
        "# for each value, convert to percent\n",
        "\n",
        "for col in scores_adjusted.columns:\n",
        "    scores_adjusted[col] = 100 * (10**scores_adjusted[col] - 1)\n",
        "    \n",
        "scores_adjusted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mean</th>\n",
              "      <th>Std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Gradient Boosting</th>\n",
              "      <td>11.396248</td>\n",
              "      <td>1.741050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Elastic Net</th>\n",
              "      <td>12.631421</td>\n",
              "      <td>3.233688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lasso</th>\n",
              "      <td>12.647068</td>\n",
              "      <td>3.253811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ridge</th>\n",
              "      <td>12.704311</td>\n",
              "      <td>3.121104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Linear Scaled Model</th>\n",
              "      <td>12.808072</td>\n",
              "      <td>3.101599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forest</th>\n",
              "      <td>13.311050</td>\n",
              "      <td>1.802810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>19.227476</td>\n",
              "      <td>1.371761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision Tree</th>\n",
              "      <td>21.862697</td>\n",
              "      <td>2.530867</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Mean       Std\n",
              "Gradient Boosting    11.396248  1.741050\n",
              "Elastic Net          12.631421  3.233688\n",
              "Lasso                12.647068  3.253811\n",
              "Ridge                12.704311  3.121104\n",
              "Linear Scaled Model  12.808072  3.101599\n",
              "Random Forest        13.311050  1.802810\n",
              "KNN                  19.227476  1.371761\n",
              "Decision Tree        21.862697  2.530867"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# creating a new df with the mean and std of each model\n",
        "\n",
        "scores_mean_std = pd.DataFrame({'Mean': scores_adjusted.mean(),\n",
        "                                'Std': scores_adjusted.std()})\n",
        "scores_mean_std.sort_values(by='Mean', inplace=True, ascending=True)\n",
        "\n",
        "scores_mean_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparing Lasso to Linear Scaled Model\n",
            "T-statistic: -0.11\n",
            "p-value: 0.91\n",
            "Results are not significant\n",
            "\n",
            "\n",
            "Comparing Ridge to Linear Scaled Model\n",
            "T-statistic: -0.07\n",
            "p-value: 0.94\n",
            "Results are not significant\n",
            "\n",
            "\n",
            "Comparing Decision Tree to Linear Scaled Model\n",
            "T-statistic: 7.15\n",
            "p-value: 0.00\n",
            "Model is better than baseline\n",
            "\n",
            "\n",
            "Comparing Random Forest to Linear Scaled Model\n",
            "T-statistic: 0.44\n",
            "p-value: 0.66\n",
            "Results are not significant\n",
            "\n",
            "\n",
            "Comparing Gradient Boosting to Linear Scaled Model\n",
            "T-statistic: -1.26\n",
            "p-value: 0.23\n",
            "Model is better than baseline\n",
            "\n",
            "\n",
            "Comparing KNN to Linear Scaled Model\n",
            "T-statistic: 5.99\n",
            "p-value: 0.00\n",
            "Model is better than baseline\n",
            "\n",
            "\n",
            "Comparing Elastic Net to Linear Scaled Model\n",
            "T-statistic: -0.12\n",
            "p-value: 0.90\n",
            "Results are not significant\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "base_line = scores_adjusted['Linear Scaled Model']\n",
        "\n",
        "for col in scores_adjusted.columns:\n",
        "    if col != 'Linear Scaled Model':\n",
        "        print(f'Comparing {col} to Linear Scaled Model')\n",
        "        compare_scores(scores_adjusted[col], base_line)\n",
        "        print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Three models demonstrate superior performance compared to the baseline model:\n",
        "\n",
        "- Decision Tree\n",
        "- Gradient Boosting\n",
        "- k-Nearest Neighbors (kNN)\n",
        "\n",
        "Making the t-test again, with Gradient Boosting being the new baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparing Decision Tree to Gradient Boosting\n",
            "T-statistic: 10.77\n",
            "p-value: 0.00\n",
            "Model is better than baseline\n",
            "\n",
            "\n",
            "Comparing KNN to Gradient Boosting\n",
            "T-statistic: 11.17\n",
            "p-value: 0.00\n",
            "Model is better than baseline\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "new_base_line = scores_adjusted['Gradient Boosting']\n",
        "\n",
        "for col in ['Decision Tree', 'KNN']:\n",
        "    print(f'Comparing {col} to Gradient Boosting')\n",
        "    compare_scores(scores_adjusted[col], new_base_line)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Both are statistically better than gradient boosting. It`s necessary do another t-test to choose the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T-statistic: -2.89\n",
            "p-value: 0.01\n",
            "Model is better than baseline\n"
          ]
        }
      ],
      "source": [
        "new_base_line = scores_adjusted['Decision Tree']\n",
        "\n",
        "compare_scores(scores_adjusted['KNN'], new_base_line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, KNN is statistically better than Decision Tree, being the best model for this problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Measuring the performance of the best model on the test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_model = knn_best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "ypred = final_model.predict(Xtest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE: 0.08\n"
          ]
        }
      ],
      "source": [
        "RMSE = np.sqrt(mean_squared_error(ytest, ypred))\n",
        "\n",
        "print(f'RMSE: {RMSE:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average error is 19.59%\n"
          ]
        }
      ],
      "source": [
        "error_percent = 100 * (10**RMSE - 1)\n",
        "\n",
        "print(f'Average error is {error_percent:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This model has an average error `19.59%`, very close when calculated on the training set (`19.22%`). This means that the model is not overfitting, and it is generalizing well to unseen data.\n",
        "\n",
        "However, with this error, the model has not a performance good enough to be used in production, but it can be used to give a rough estimate of the price of a house, given its features, for a initial aproximation it`s good enough.\n",
        "\n",
        "For a future work, we could try to improve the model performance, by doing a more thorough feature engineering, and also by trying other models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Retreing the model with the full dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor(n_neighbors=6, p=1, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor(n_neighbors=6, p=1, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsRegressor(n_neighbors=6, p=1, weights='distance')"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_model.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "# exporting the model\n",
        "\n",
        "path = pathlib.Path.cwd().parent / 'final_model.pkl'\n",
        "\n",
        "with open(path, 'wb') as f:\n",
        "    pickle.dump(final_model, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsRegressor(n_neighbors=6, p=1, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor(n_neighbors=6, p=1, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "KNeighborsRegressor(n_neighbors=6, p=1, weights='distance')"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# reading the final model\n",
        "\n",
        "path = pathlib.Path.cwd().parent / 'final_model.pkl'\n",
        "\n",
        "with open(path, 'rb') as f:\n",
        "    final_model = pickle.load(f)\n",
        "    \n",
        "final_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Showing the features with the highest importance "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Feature</th>\n",
              "      <th>Importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>House.Age</td>\n",
              "      <td>0.269225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Garage.Age</td>\n",
              "      <td>0.165178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Remod.Age</td>\n",
              "      <td>0.101383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Mo.Sold</td>\n",
              "      <td>0.019573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>TotRms.AbvGrd</td>\n",
              "      <td>0.011612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Overall.Qual</td>\n",
              "      <td>0.010890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Yr.Sold</td>\n",
              "      <td>0.007928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Gr.Liv.Area</td>\n",
              "      <td>0.007613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>X1st.Flr.SF</td>\n",
              "      <td>0.007092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Overall.Cond</td>\n",
              "      <td>0.006768</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Feature  Importance\n",
              "46      House.Age    0.269225\n",
              "44     Garage.Age    0.165178\n",
              "45      Remod.Age    0.101383\n",
              "40        Mo.Sold    0.019573\n",
              "26  TotRms.AbvGrd    0.011612\n",
              "4    Overall.Qual    0.010890\n",
              "41        Yr.Sold    0.007928\n",
              "18    Gr.Liv.Area    0.007613\n",
              "15    X1st.Flr.SF    0.007092\n",
              "5    Overall.Cond    0.006768"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "result = permutation_importance(final_model, X, y, n_repeats=10, random_state=RANDOM_SEED)\n",
        "\n",
        "feature_importance = pd.DataFrame(\n",
        "    {\n",
        "        'Feature': data.drop(columns=['SalePrice']).columns,\n",
        "        'Importance': result.importances_mean\n",
        "    }\n",
        ")\n",
        "\n",
        "feature_importance.sort_values(by='Importance', ascending=False, inplace=True)\n",
        "\n",
        "\n",
        "feature_importance.head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this model, the most important features are:\n",
        "\n",
        "- **House Age**: the age of the house\n",
        "- **Garage Age**: the age of the garage\n",
        "- **Remond Age**: the age of the remodelling, or the same as the age of the house if there was no remodelling\n",
        "- **Mo.sold**: the month of the year when the house was sold\n",
        "- **TotRms.AbvGrd**: total rooms above ground\n",
        "- **Overall.Qual**: overall material and finish quality\n",
        "\n",
        "It means that the age, in general, is the most important feature for the model, followed by the month of the year when the house was sold, and the number of rooms above ground.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
